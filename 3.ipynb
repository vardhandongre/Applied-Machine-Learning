{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 498AM1 Applied Machine Learning\n",
    "## Problem 1 : Building a Naive Bayes Classifier\n",
    "### Prepared by: Vardhan Dongre (vdongre2@illinois.edu)\n",
    "\n",
    "#### Problem Description: \n",
    "Build a Naive Bayes classifier for the mathematics dataset by quantizing the dataset into 2 categories (G3 > 12 and G3 <= 12). The dataset has 30 attributes, choose suitable models for each attribute to find the class conditional probabilities.\n",
    "\n",
    "__Dataset:__ https://archive.ics.uci.edu/ml/datasets/Student+Performance \n",
    "\n",
    "\n",
    "__Part a__ : For <font color = blue>\"binary\" attributes</font>, use a <font color = blue>binomial model</font>. For the attributes described as <font color = blue>“numeric”</font> use a <font color = blue>normal model</font>. For the attributes described as <font color = blue>“nominal”</font> use a <font color = blue>multinomial model</font>\n",
    "\n",
    "__Part b__ : For <font color = blue>\"binary\" attributes</font>, use a <font color = blue>binomial model</font>. For the attributes described as <font color = blue>“numeric”</font> use a <font color = blue>multinomial model</font>. For the attributes described as <font color = blue>“nominal”</font> use a <font color = blue>multinomial model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "%matplotlib inline\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_df = pd.read_csv(\"/Users/don/Desktop/AML/student-mat.csv\", sep=\";\")\n",
    "# Drop G1 and G2 and absences\n",
    "math_df = math_df.drop(['G1', 'G2', 'absences'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes\n",
    "num_students = math_df.shape[0]\n",
    "# Binary Attributes\n",
    "binary_attributes = {'school':['GP','MS'],'sex':['F','M'], 'address':['U','R'], 'famsize':['LE3','GT3'], 'Pstatus':['T','A'], 'schoolsup':['yes','no'], 'famsup':['yes','no'], 'paid':['yes','no'], 'activities':['yes','no'], 'nursery':['yes','no'], 'higher':['yes','no'], 'internet':['yes','no'], 'romantic':['yes','no']}\n",
    "# Nominal Attributes\n",
    "nominal_attributes = {'Mjob':['teacher','health','services','at_home','other'], 'Fjob':['teacher','health','services','at_home','other'], 'reason':['home', 'reputation', 'course', 'other'], 'guardian':['mother', 'father', 'other']}\n",
    "# Numeric Attributes\n",
    "numeric_attributes = {'age','Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel','freetime', 'goout', 'Dalc', 'Walc', 'health'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>10.415190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>4.581443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "               G3  \n",
       "count  395.000000  \n",
       "mean    10.415190  \n",
       "std      4.581443  \n",
       "min      0.000000  \n",
       "25%      8.000000  \n",
       "50%     11.000000  \n",
       "75%     14.000000  \n",
       "max     20.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NA values\n",
    "#math_df.isnull().sum()\n",
    "# Check for Unique Vals\n",
    "#math_df.nunique(axis=0)\n",
    "math_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Probabilities\n",
    "def numeric_prob(data):\n",
    "    numeric_prob = {}\n",
    "    for i in numeric_attributes:\n",
    "        numeric_prob[i] = data[i].value_counts(normalize=True).to_dict()\n",
    "    return numeric_prob\n",
    "\n",
    "# Nominal Probabilities\n",
    "def nominal_prob(data):\n",
    "    nominal_prob = {}\n",
    "    for i in nominal_attributes:\n",
    "        nominal_prob[i] = data[i].value_counts(normalize=True).to_dict()\n",
    "    return nominal_prob\n",
    "\n",
    "# Binary Probabilities\n",
    "def binary_prob(data):\n",
    "    bin_prob = {}\n",
    "    for i in binary_attributes:\n",
    "        bin_prob[i] = data[i].value_counts(normalize=True).to_dict()\n",
    "    return bin_prob\n",
    "\n",
    "# Gaussian Distribution\n",
    "def normal_prob(data):\n",
    "    #norm_prob = {}\n",
    "    for i in numeric_attributes:\n",
    "        mu = mean(data[i])\n",
    "        sigma = std(data[i])\n",
    "        dist = norm(mu, sigma)\n",
    "        #norm_prob[i] = dist.pdf(data[i])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bayes' Rule, for classification we need:\n",
    "$$ \\Big[\\Pi_j\\Big( p(x^{(j)}|y )\\Big)p(y)\\Big]$$\n",
    "\n",
    "Since we need to find the class conditional probabilities to evaluate the above rule, the following function finds the class conditional probabilities for each attribute and then gives the following probabilities:\n",
    "\n",
    "$$prob_0: \\Pi_j\\Big( p(x^{(j)}|y=0)\\Big)$$\n",
    "$$prob_1: \\Pi_j\\Big( p(x^{(j)}|y=1)\\Big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConditionalProbsModelB(data):\n",
    "    col= X.columns\n",
    "    prob_1 = np.zeros(len(data))\n",
    "    prob_0 = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        pro_1=1\n",
    "        pro_0=1\n",
    "        for k in col:\n",
    "            #print(i,k)\n",
    "            if(k in binary_attributes):\n",
    "                cate=\"binary\"\n",
    "            if(k in nominal_attributes):\n",
    "                cate=\"nominal\"\n",
    "            if(k in numeric_attributes):\n",
    "                cate=\"numeric\"\n",
    "            if(cate==\"binary\"):\n",
    "                if(data.iloc[i][k] in tr_bin_prob_0[k]):\n",
    "                    pr_0=tr_bin_prob_0[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_0 = 0.00001\n",
    "                if(data.iloc[i][k] in tr_bin_prob_1[k]):\n",
    "                    pr_1=tr_bin_prob_1[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_1 = 0.00001\n",
    "            if(cate==\"nominal\"):\n",
    "                if(data.iloc[i][k] in tr_nom_prob_0[k]):\n",
    "                    pr_0=tr_nom_prob_0[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_0 = 0.00001\n",
    "                if(data.iloc[i][k] in tr_nom_prob_1[k]):\n",
    "                    pr_1=tr_nom_prob_1[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_1 = 0.00001\n",
    "            if(cate==\"numeric\"):\n",
    "                if(data.iloc[i][k] in tr_num_prob_0[k]):\n",
    "                    pr_0=tr_num_prob_0[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_0 = 0.00001\n",
    "                if(data.iloc[i][k] in tr_num_prob_1[k]):\n",
    "                    pr_1=tr_num_prob_1[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_1 = 0.00001\n",
    "        pro_1*=pr_1\n",
    "        pro_0*=pr_0\n",
    "        prob_1[i] = pro_1\n",
    "        prob_0[i] = pro_0\n",
    "    return prob_0, prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConditionalProbsModelA(data):\n",
    "    col= X.columns\n",
    "    prob_1 = np.zeros(len(data))\n",
    "    prob_0 = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        pro_1=1\n",
    "        pro_0=1\n",
    "        for k in col:\n",
    "            #print(i,k)\n",
    "            if(k in binary_attributes):\n",
    "                cate=\"binary\"\n",
    "            if(k in nominal_attributes):\n",
    "                cate=\"nominal\"\n",
    "            if(k in numeric_attributes):\n",
    "                cate=\"numeric\"\n",
    "            if(cate==\"binary\"):\n",
    "                if(data.iloc[i][k] in tr_bin_prob_0[k]):\n",
    "                    pr_0=tr_bin_prob_0[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_0 = 0.00001\n",
    "                if(data.iloc[i][k] in tr_bin_prob_1[k]):\n",
    "                    pr_1=tr_bin_prob_1[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_1 = 0.00001\n",
    "            if(cate==\"nominal\"):\n",
    "                if(data.iloc[i][k] in tr_nom_prob_0[k]):\n",
    "                    pr_0=tr_nom_prob_0[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_0 = 0.00001\n",
    "                if(data.iloc[i][k] in tr_nom_prob_1[k]):\n",
    "                    pr_1=tr_nom_prob_1[k][data.iloc[i][k]]\n",
    "                else:\n",
    "                    pr_1 = 0.00001\n",
    "            if(cate==\"numeric\"):\n",
    "                #if(data.iloc[i][k] in tr_num_prob_0[k]):\n",
    "                    pr_0=tr_norm_dist_0.pdf(data.iloc[i][k])\n",
    "                #else:\n",
    "                #    pr_0 = 0.00001\n",
    "                #if(data.iloc[i][k] in tr_num_prob_1[k]):\n",
    "                    pr_1=tr_norm_dist_1.pdf(data.iloc[i][k])\n",
    "                #else:\n",
    "                #    pr_1 = 0.00001\n",
    "        pro_1*=pr_1\n",
    "        pro_0*=pr_0\n",
    "        prob_1[i] = pro_1\n",
    "        prob_0[i] = pro_0\n",
    "    return prob_0, prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(A,B):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(A)):\n",
    "        #print(A[i])\n",
    "        if A[i] == B.iloc[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    return correct/(correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = math_df.iloc[:,:29]\n",
    "y = math_df['G3']\n",
    "train_score = np.zeros(10)\n",
    "test_score = np.zeros(10)\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "    X_0 = y_train<=12\n",
    "    X_1 = y_train>12\n",
    "    # Quantize data in two classes G3 <= 12(0) and G3 > 12(1)\n",
    "    Xy0 = X_train[X_0]\n",
    "    Xy1 = X_train[X_1]\n",
    "\n",
    "########################### (Part-b) #############################\n",
    "# # Training \n",
    "\n",
    "#     # Probabilities\n",
    "#     tr_priory0 = len(Xy0)/len(X_train)\n",
    "#     tr_priory1 = len(Xy1)/len(X_train)\n",
    "#     # Conditional Probabilities for training data (>12)\n",
    "#     tr_num_prob_1 = numeric_prob(Xy1) # Numeric Attributes (Multinomial Model)\n",
    "#     tr_nom_prob_1 = nominal_prob(Xy1) # Nominal Attributes (Multinomial Model)\n",
    "#     tr_bin_prob_1 = binary_prob(Xy1) # Binary Attributes (Binomial Model)\n",
    "\n",
    "#     # Conditional Probabilities for training data (<=12)\n",
    "#     tr_num_prob_0 = numeric_prob(Xy0) # Numeric Attributes (Multinomial Model)\n",
    "#     tr_nom_prob_0 = nominal_prob(Xy0) # Nominal Attributes (Multinomial Model)\n",
    "#     tr_bin_prob_0 = binary_prob(Xy0) # Binary Attributes (Binomial Model)\n",
    "    \n",
    "#     tr_prob_0, tr_prob_1 = ConditionalProbsModelB(X_train)\n",
    "#     tr_py0 = tr_priory0*tr_prob_0\n",
    "#     tr_py1 = tr_priory1*tr_prob_1\n",
    "#     guess_tr = tr_py1>tr_py0\n",
    "#     tr_compare = y_train > 12\n",
    "#     train_score[i] = accuracy(guess_tr, tr_compare)\n",
    "\n",
    "# # Testing\n",
    "\n",
    "#     te_prob_0, te_prob_1 = ConditionalProbsModelB(X_test)\n",
    "#     te_py0 = tr_priory0*te_prob_0\n",
    "#     te_py1 = tr_priory1*te_prob_1\n",
    "#     guess_te = te_py1>te_py0\n",
    "#     te_compare = y_test > 12\n",
    "#     test_score[i] = accuracy(guess_te, te_compare)\n",
    "    \n",
    "########################### (Part-a) #############################\n",
    "# Training\n",
    "\n",
    "    # Probabilities\n",
    "    tr_priory0 = len(Xy0)/len(X_train)\n",
    "    tr_priory1 = len(Xy1)/len(X_train)\n",
    "    # Conditional Probabilities for training data (>12)\n",
    "    tr_norm_dist_1 = normal_prob(Xy1) # Numeric Attributes (Normal (Gaussian) Model)\n",
    "    tr_nom_prob_1 = nominal_prob(Xy1) # Nominal Attributes (Multinomial Model)\n",
    "    tr_bin_prob_1 = binary_prob(Xy1) # Binary Attributes (Binomial Model)\n",
    "\n",
    "    # Conditional Probabilities for training data (<=12)\n",
    "    tr_norm_dist_0 = normal_prob(Xy0) # Numeric Attributes (Normal (Gaussian) Model)\n",
    "    tr_nom_prob_0 = nominal_prob(Xy0) # Nominal Attributes (Multinomial Model)\n",
    "    tr_bin_prob_0 = binary_prob(Xy0) # Binary Attributes (Binomial Model)\n",
    "\n",
    "    tr_prob_0, tr_prob_1 = ConditionalProbsModelA(X_train)\n",
    "    tr_py0 = tr_priory0*tr_prob_0\n",
    "    tr_py1 = tr_priory1*tr_prob_1\n",
    "    guess_tr = tr_py1>tr_py0\n",
    "    tr_compare = y_train > 12\n",
    "    train_score[i] = accuracy(guess_tr, tr_compare)\n",
    "\n",
    "# Testing\n",
    "    \n",
    "    te_prob_0, te_prob_1 = ConditionalProbsModelA(X_test)\n",
    "    te_py0 = tr_priory0*te_prob_0\n",
    "    te_py1 = tr_priory1*te_prob_1\n",
    "    guess_te = te_py1>te_py0\n",
    "    te_compare = y_test > 12\n",
    "    test_score[i] = accuracy(guess_te, te_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part - a Accuracies\n",
    "train_score_a = train_score\n",
    "test_score_a = test_score\n",
    "# Mean and Standard Deviation of Accuracies\n",
    "# Train Accuracies\n",
    "tr_mean_a = mean(train_score)\n",
    "tr_sd_a = std(train_score)\n",
    "# Test Accuracies\n",
    "te_mean_a = mean(test_score)\n",
    "te_sd_a = std(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Part - b Accuracies\n",
    "# # Mean and Standard Deviation of Accuracies\n",
    "# # Train Accuracies\n",
    "# train_score_b = train_score\n",
    "# test_score_b = test_score\n",
    "# tr_mean_b = mean(train_score)\n",
    "# tr_sd_b = std(train_score)\n",
    "# # Test Accuracies\n",
    "# te_mean_b = mean(test_score)\n",
    "# te_sd_b = std(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_dict1 = {'Train_score_a':train_score_a, 'Train_score_b':train_score_b, 'Test_score_a':test_score_a, 'Test_score_b':test_score_b}\n",
    "summary1 = pd.DataFrame(help_dict1)\n",
    "help_dict2 ={'Train_mean_a':tr_mean_a, 'Train_mean_b':tr_mean_b, 'Test_mean_a':te_mean_a, 'Test_mean_b':te_mean_b}\n",
    "summary2 = pd.DataFrame(help_dict2, index=[0])\n",
    "help_dict3 ={'Train_sd_a':tr_sd_a, 'Train_sd_b':tr_sd_b, 'Test_sd_a':te_sd_a, 'Test_sd_b':te_sd_b}\n",
    "summary3 = pd.DataFrame(help_dict3, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing scores for the two classifiers over 10 folds are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train_score_a  Train_score_b  Test_score_a  Test_score_b\n",
      "0       0.674627       0.671642      0.633333      0.666667\n",
      "1       0.680597       0.659701      0.600000      0.733333\n",
      "2       0.659701       0.656716      0.716667      0.750000\n",
      "3       0.668657       0.671642      0.666667      0.650000\n",
      "4       0.662687       0.671642      0.700000      0.666667\n",
      "5       0.653731       0.689552      0.750000      0.550000\n",
      "6       0.659701       0.674627      0.716667      0.650000\n",
      "7       0.668657       0.674627      0.666667      0.650000\n",
      "8       0.677612       0.698507      0.616667      0.500000\n",
      "9       0.650746       0.680597      0.766667      0.600000\n"
     ]
    }
   ],
   "source": [
    "print(summary1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracies obtained in Part a and b have the following statistics:\n",
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train_mean_a  Train_mean_b  Test_mean_a  Test_mean_b\n",
      "0      0.665672      0.674925     0.683333     0.641667\n"
     ]
    }
   ],
   "source": [
    "print(summary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train_sd_a  Train_sd_b  Test_sd_a  Test_sd_b\n",
      "0    0.009534    0.011824   0.053229   0.071976\n"
     ]
    }
   ],
   "source": [
    "print(summary3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which classifier is more accurate and why?\n",
    "\n",
    "The difference between the two classfiers is the event models for the numeric features. The normal distribution is a suitable model for continuous type attributes while multinomial is suitable for feature with finite categories. From the above statistics we can see that the mean accuracy on test data in part a is higher than that of part b as well as the standard deviation for part a is smaller than that of part b, thus we can conclude from this data that classifier A performed better than Classifier B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
